#'Exploratory Data Analysis
#'
#'@description Exploratory data analysis to identify possible sample swaps and
#'  technical outliers
#'@param RGset The RGset generated by the function loadingSamples. The pData
#'  data.frame requires a column called "ID", which is a unique identifier for
#'  each sample. The pData data.frame also requires a column called "Sex", which
#'  can only take three possible character values: 'Female', 'Male', or
#'  'Unknown'.
#'@param globalvarexplore A vector of characteristic column names to explore in
#'  association with the first 12 principle components. These column names must
#'  be in the pData frame of the RGset specified by the RGset argument
#'@param DetectionPvalMethod A character string indicating the detection p-value
#'  method to use; options include: SeSAME method ("SeSAMe"; default) or
#'  ewastools method ("ewastools").
#'@param DetectionPvalCutoff a numeric value indicating the detection p-value
#'  cut-off (default=0.05)
#'@param minNbeads a numeric value indicating the minimum number of beads to
#'  include a beta-value (default=0; a value of 0 corresponds to no filtering)
#'@param FilterZeroIntensities a logic statement (TRUE/FALSE; default=FALSE).
#'@param destinationfolder A character string indicating the location where
#'  files should be saved, e.g. "C:\\Home\\PACE\\BirthSize"
#'@param savelog logic; TRUE indicates to save a log of the functions run
#'  (default)
#'@param cohort A character string for the cohort's acronym (e.g. "HEBC")
#'@param analysisdate A character string indicating the date the analysis was
#'  run. Please specify in the form: YEARMONTHDAY, e.g. "20200205" for February
#'  5th 2020
#'@details The sesame package is used to calculate the detection p-values.
#'  Samples to exclude based on whether they look like a sex mix-up, and poor
#'  detection p-values (detection p-value>0.05) for more than 5 percent of
#'  probes.
#'@return PDFs/PNGs of exploratory data analysis in "EDA" subfolder of "Output"
#'  folder, including: red/green signal intensities, distribution of intensity
#'  across all sites, heatmap of chrY, signal intensities on X and Y
#'  chromosomes, dendogram and heatmap of the SNPs on the array (to identify
#'  possible sample replications or appraise relatedness), a heatmap of the
#'  posterior probabilities that the SNP distribution is of the outlier
#'  component, scatterplot of first two PCs, boxplots of batch and other
#'  characteristics (if indicated) vs the top principle components, csv file of
#'  suggested probes to remove based on the percent of samples that failed for
#'  that probe (see function details), csv file of suggested samples to
#'  potentially remove based on evidence of sex mix-ups, a high proportion of
#'  failed probes for that sample, indication of sample contamination, low
#'  global methylated or unmethylated intensities, or unintentional replicates
#'  based on clustering of SNP probes (see dendogram and heatmap of the SNPs on
#'  the array). Also returns a list that includes: \item{SamplestoRemove}{A
#'  character vector of Basenames to exclude based on evidence of sex mix-ups,
#'  or a high proportion of failed probes for that sample. This vector does not
#'  the suspected unintentional replicates; we suggest users check the SNP
#'  dendogram to evaluate this themselves.} \item{ProbestoRemove}{A character
#'  vector of CpGIDs to exclude based on the exploratory data analysis}
#'  \item{DetectionPval}{A matrix of detection p-values}
#'  \item{IndicatorGoodIntensity}{A matrix used to mask methylation values with
#'  a poor intensity value based on the number of beads (if minNbeads is larger
#'  than zero) and intensity values of zero (if FilterZeroIntensities=TRUE); NA
#'  if poor intensity value and 1 otherwise}\item{logOddsContamin}{The average
#'  log odds from the SNP posterior probabilities from the outlier component;
#'  capturing how irregular the SNP beta-values deviate from the ideal trimodal
#'  distribution. Values greater than -4 are suggest potentially contaminated
#'  samples}
#'@examples
#'\dontrun{
#'EDAtrying<-ExploratoryDataAnalysis(RGset=exampledat,
#'                                   globalvarexplore=c("Sex","BWT"),
#'                                   DetectionPvalMethod="SeSAMe",
#'                                   DetectionPvalCutoff=0.05,
#'                                   minNbeads=3,
#'                                   FilterZeroIntensities=FALSE,
#'                                   destinationfolder="H:/UCLA/PACE/Birthweight-placenta",
#'                                   savelog=TRUE,
#'                                   cohort="HEBC",analysisdate="20200710")
#'}

ExploratoryDataAnalysis<-function(RGset=NULL,globalvarexplore=NULL,
                                  DetectionPvalMethod=NULL,
                                  DetectionPvalCutoff=0.05,
                                  minNbeads=0,
                                  FilterZeroIntensities=FALSE,
                                  destinationfolder=NULL,
                                  savelog=TRUE,cohort=NULL,analysisdate=NULL){

  if(is.null(destinationfolder)) stop("Please specify a destination folder")

  ## Checking that base output folder is in the directory, if not there, creating it
  BaseOutputname<-paste(cohort,"_",analysisdate,"_Output",sep="")
  setwd(destinationfolder)
  tempdir<-dir()
  if(!(BaseOutputname %in% tempdir)) dir.create(file.path(destinationfolder, BaseOutputname), showWarnings = FALSE)

  Outputname<-paste(cohort,"_",analysisdate,"_Output/EDA",sep="")
  dir.create(file.path(destinationfolder, Outputname), showWarnings = FALSE)
  destinationfolder<-paste(destinationfolder,Outputname,sep="/")
  setwd(destinationfolder)

  if(!is.null(globalvarexplore)){
    if(FALSE %in% (globalvarexplore %in% colnames(pData(RGset)))) stop("One of the variables in 'globalvarexplore' is not in the dataset")
  }

  ## sesame functions have been updated, need to check have newest version
  temparguments<-formals(sesame::pOOBAH)
  if(!("return.pval" %in% names(temparguments))) stop("the sesame package needs to be updated before running this function")

  ## other input checks
  if(!("Sex" %in% colnames(pData(RGset)))) stop("Variable 'Sex' is required and not in the dataset; see function arguments for specification")
  if(!("ID" %in% colnames(pData(RGset)))) stop("Variable 'ID' is required and not in the dataset; see function arguments for specification")
  if(!("Basename" %in% colnames(pData(RGset)))) stop("Variable 'Basename' is required and not in the dataset")
  if(!(DetectionPvalMethod %in% c("SeSAMe","ewastools"))) stop("Detection p-value method must be  'SeSAMe' or 'ewastools'")

  if(savelog){

    sink()
    sink(type="message")

    con <- file("log_step2.log")
    sink(con, append=TRUE)
    sink(con, append=TRUE, type="message")

  }

  ## Filtering bad intensities based on the number of beads and zero intensities
  tempfilteringRGset <- probeFiltering(RGset,cutbead=minNbeads,zeroint=FilterZeroIntensities)
  indicatorgoodintensity<-getBeta(tempfilteringRGset)
  indicatorgoodintensity[!is.na(indicatorgoodintensity)]<-1

  RGset<-as(RGset,"RGChannelSet")

  ## Getting Raw Betas
  rawbetas<-preprocessRaw(RGset)
  justbetas<-getBeta(rawbetas)
  justMvals<-getM(rawbetas)
  qc<-getQC(rawbetas)

  ## Functional Normalization (This step takes a while and requires lots of memory):
  Mset.norm = preprocessFunnorm(RGset, sex = NULL, bgCorr = T, dyeCorr = T, nPCs = 2, verbose = TRUE)
  justbetas.norm<-getBeta(Mset.norm)

  ## Characterizing the log2 Median Unmethylated and Methylated Intensities
  png(paste(cohort,"_",analysisdate,"_Methyl_and_Unmethyl_Signal_Intensities.png",sep=""))
  plotQC(qc)
  dev.off()

  tempmeds <- (qc$mMed + qc$uMed)/2
  whichBad <- which((tempmeds < 10.5))
  gettingmedianintensities<-data.frame(Basename=pData(rawbetas)$Basename,UnmethylMedInt=qc$uMed,MethylMedInt=qc$mMed,IntensityCat="Good")
  gettingmedianintensities$IntensityCat<-as.character(gettingmedianintensities$IntensityCat)
  gettingmedianintensities$Basename<-as.character(gettingmedianintensities$Basename)
  gettingmedianintensities$IntensityCat[which(tempmeds < 10.5)]<-"Bad"

  ## Plotting SNP Data
  SNPs<- getSnpBeta(RGset)
  colnames(SNPs)<-pData(rawbetas)$ID

  #hc = hclust(dist(t(SNPs)))
  #hcd = as.dendrogram(hc)
  clusters <- pvclust::pvclust(SNPs, method.dist="correlation",
                      method.hclust="average", nboot=1000)

  pdf(paste(cohort,"_",analysisdate,"_Dendrogram_based_on_Array_SNPs.pdf",sep=""), width = ncol(SNPs)*0.6, height = 8)
  plot(clusters,main="Dendrogram based on Array SNPs")
  pvclust::pvrect(clusters)
  dev.off()

  hmcols <- gplots::colorpanel(2750, "yellow", "black", "blue")
  pdf(paste(cohort,"_",analysisdate,"_Heatmap_of_SNPs.pdf",sep=""),width = ncol(SNPs)*0.2, height = 10)
  gplots::heatmap.2(SNPs, key = FALSE, trace = "none", dendrogram = "column",
            lwid = c(0.5, 8), lhei = c(2, 7),srtCol=45,margins=c(6,0.5),
            col = hmcols,
            labCol = pData(rawbetas)$Basename,
            labRow = NA)
  dev.off()

  tempclusters<-pvclust::pvpick(clusters)$clusters
  if(length(tempclusters)>0){
    names(tempclusters)<-paste("Cluster",c(1:length(tempclusters)),sep="_")
    tempclusters<-plyr::ldply(tempclusters,function(x)data.frame(ID=x))
    colnames(tempclusters)[which(colnames(tempclusters)==".id")]<-"Cluster"
    pDatainfo<-as.data.frame(pData(Mset.norm))[,c("ID","Basename")]
    tempclusters<-merge(tempclusters,pDatainfo,by="ID")
    tempclusters$Basename<-as.character(tempclusters$Basename)
    tempclusters<-unique(tempclusters)
  }

  ## Evaluating potential contamination based on SNP data
  contaminationSNPs<-ewastools::call_genotypes(SNPs, learn=FALSE)

  outlierprob <- contaminationSNPs$outliers
  colnames(outlierprob)<-colnames(SNPs)
  rownames(outlierprob)<-rownames(SNPs)

  outlierprob[outlierprob==0]<-0.0001 ## to prevent -Inf values
  outlierprob[outlierprob==1]<-0.9999 ## to prevent Inf values

  log_odds = outlierprob/(1 - outlierprob)
  meanlogodds = colMeans(log2(log_odds), na.rm = TRUE)
  meanlogoddsBin<-ifelse(meanlogodds>(-4),"Bad","Good") ## using >-4 as the suggested cut-off
  contaminationdat<-data.frame(Basename=sampleNames(RGset),Contamination=meanlogoddsBin,Meanlog2oddsContamination=meanlogodds)

  ## adding a color indicator that sample is potentially poor quality
  colcolorsBad<-as.factor(meanlogoddsBin)
  levels(colcolorsBad)<-c("#9e9ac8","#3f007d")
  colcolorsBad<-as.character(colcolorsBad)
  allcolcolors<-cbind(colcolorsBad,colcolorsBad)
  colnames(allcolcolors)<-NULL

  pdf(paste(cohort,"_",analysisdate,"_Heatmap_SNP_Outliers_Suggesting_Contamination.pdf",sep=""),width = ncol(SNPs)*0.2, height = 10)
  heatmap.plus::heatmap.plus(outlierprob,
                             distfun = dist,
                             hclustfun = hclust,
                             na.rm=TRUE,
                             scale="none",
                             margins=c(10,5),
                             ColSideColors=allcolcolors,
                             main="Posterior Probabilities")
  dev.off()


  annotdat<-as.data.frame(getAnnotation(Mset.norm))
  annotdat$chr<-as.character(annotdat$chr)
  annotdat_XY<-annotdat[which(annotdat$chr=="chrX" | annotdat$chr=="chrY"),]

  ## Calculate the variance of each probe and remove any with a variance of 0 prior to PCA
  vars = as.matrix(rowVars(justMvals))

  ## Replace all probes with no variance with NA and remove them from the Mval set
  vars[vars == 0] = NA
  vars = na.omit(vars)
  intersect = intersect(rownames(vars), rownames(justMvals))
  justMvals = justMvals[intersect,]

  ## Removing sex chromosomes before PCA
  justMvals <- justMvals[!(rownames(justMvals) %in% rownames(annotdat_XY)),]

  pcadataall<-prcomp(t(na.omit(justMvals)), retx = T, center = T, scale. = T)
  tempimportance<-summary(pcadataall)$importance
  PC1label<-paste("PC1 (",round(tempimportance[2,1]*100,2),"% of Variance)",sep="")
  PC2label<-paste("PC2 (",round(tempimportance[2,2]*100,2),"% of Variance)",sep="")
  pcadata<-as.data.frame(pcadataall$x)
  pcadata$Individual<-pData(rawbetas)$ID

  p<-ggplot(pcadata,aes(PC1,PC2))+
    geom_point(size=5,col="darkblue",alpha=0.8)+
    geom_text(aes(label=Individual),hjust=-0.2)+
    theme_bw()+
    xlab(PC1label)+
    ylab(PC2label)+
    theme(axis.title=element_text(face="bold",size=16),
          legend.position="none")

  ggsave(filename=paste(cohort,"_",analysisdate,"_PCA_of_Raw_Data.png",sep=""),
         plot=p,width=10,height=10,units="in")

  if("Batch" %in% colnames(pData(RGset))) globalvarexplore<-c(globalvarexplore,"Batch")

  if(length(globalvarexplore)>0){

    globalvarexplore<-unique(globalvarexplore)
    pcadata<-as.data.frame(pcadataall$x)
    maxPCs<-min(c(12,ncol(pcadata)))
    pcadata<-pcadata[,paste("PC",1:maxPCs,sep="")]
    pcadata$ID<-pData(rawbetas)$ID

    for(i in globalvarexplore){

      temppcadata<-pcadata
      temppcadata$TempVar<-pData(rawbetas)[,i]
      temppcadata<-reshape::melt(temppcadata,id=c("ID","TempVar"))
      temppcadata$NumPClab<-as.numeric(sub("PC","",as.character(temppcadata$variable)))

      if(is.numeric(temppcadata$TempVar)){

        labelinfo<-plyr::ddply(temppcadata,.(variable),function(x) paste("p=",format(round(cor.test(x$value,x$TempVar)$p.value,3),nsmall=3),sep=""))

      } else {

        temppcadata$TempVar<-as.factor(temppcadata$TempVar)
        labelinfo<-plyr::ddply(temppcadata,.(variable),function(x) paste("p=",format(round(summary(aov(value~TempVar,data=x))[[1]]["TempVar","Pr(>F)"],3),nsmall=3),sep=""))

      }

      labelinfo$PropofVar<-paste("% of Var=",format(round(tempimportance[2,1:maxPCs]*100,2),nsmall=2),sep="")
      temppcadata<-merge(temppcadata,labelinfo,by="variable")
      temppcadata$label<-paste(temppcadata$variable,"\n",temppcadata$PropofVar,"\n",temppcadata$V1,sep="")
      temppcadata<-temppcadata[order(temppcadata$NumPClab),]
      temppcadata$label<-as.factor(temppcadata$label)
      temppcadata$label<-factor(temppcadata$label,levels=unique(temppcadata$label))

      if(is.numeric(temppcadata$TempVar)){

        p<-ggplot(temppcadata,aes(TempVar,value))+
          geom_point()+
          stat_smooth(method="lm",se=FALSE)

      } else {

        p<-ggplot(temppcadata,aes(TempVar,value))+
          geom_boxplot(outlier.shape=NA)+
          geom_jitter()

      }

      p<- p +
        facet_wrap(~label,ncol=3,scales="free_y")+
        theme_bw()+
        xlab(i)+
        theme(axis.title=element_text(face="bold",size=14))

      ggsave(filename=paste(cohort,"_",analysisdate,"_Association_between_",i,"_and_Top_PCs_Raw_Data.png",sep=""),
             plot=p,width=10,height=10,units="in")

    }

  }

  hmcols <- gplots::colorpanel(2750, "yellow", "black", "blue")
  colcolorsSex<-as.factor(pData(Mset.norm)$Sex)
  levels(colcolorsSex)<-c("#a6cee3","#1f78b4")
  colcolorsSex<-as.character(colcolorsSex)
  allcolcolors<-cbind(colcolorsSex,colcolorsSex)
  colnames(allcolcolors)<-NULL

  SexChr<-Mset.norm[which(getAnnotation(Mset.norm)$chr=="chrY"),]
  methyldata<-getBeta(SexChr)

  pdf(paste(cohort,"_",analysisdate,"_Heatmap_of_Y_Chromosome_by_Sex.pdf",sep=""), width = ncol(methyldata)*0.2, height = 10)
  heatmap.plus::heatmap.plus(methyldata,
               distfun = dist,
               hclustfun = hclust,
               na.rm=TRUE,
               scale="none",
               labRow=NA,
               labCol=pData(SexChr)$Basename,
               Rowv=NA,
               col=hmcols,
               ColSideColors=allcolcolors,
               main="Heatmap of Y Chromosome by Sex")
  dev.off()

  ## Check whether reported sex matches inferred sex ()
  pred.sex = data.frame(getSex(Mset.norm))

  png(paste(cohort,"_",analysisdate,"_Signal_Intensities_on_X_and_Y_Chromosomes_by_Sex.png",sep=""))
  plotSex(Mset.norm,id=pData(Mset.norm)$Sex)
  dev.off()

  SexMixupV1<-pData(Mset.norm)$Basename[which(pData(Mset.norm)$Sex=="Male" & pData(Mset.norm)$predictedSex=="F")]
  cat("Original sex was M and predicted sex was F for: ",paste(SexMixupV1,collapse="; "),"\n")

  SexMixupV2<-pData(Mset.norm)$Basename[which(pData(Mset.norm)$Sex=="Female" & pData(Mset.norm)$predictedSex=="M")]
  cat("Original sex was F and predicted sex was M for: ",paste(SexMixupV2,collapse="; "),"\n")

  ## Check distributions before and after normalization
  png(file=paste(cohort,"_",analysisdate,"_BetaValue_Distributions_BeforeQC.png",sep=""),width=1400,height=700,pointsize=12)

  par(mfrow=c(1,2))

  if("Batch" %in% colnames(pData(RGset))){
    densityPlot(justbetas, sampGroups = pData(rawbetas)$Batch, legend=FALSE, main = "Raw Betas", xlab = "Beta")
    densityPlot(justbetas.norm, sampGroups = pData(Mset.norm)$Batch, legend=FALSE, main = "FunNorm Adjusted Betas", xlab = "Beta")
  } else {
    densityPlot(justbetas, main = "Raw Betas", xlab = "Beta")
    densityPlot(justbetas.norm, main = "FunNorm Adjusted Betas", xlab = "Beta")
  }

  dev.off()

  cat("Calculating detection p-values...","\n")

  if(DetectionPvalMethod=="SeSAMe") {
    ## Use sesame to calculate the detection p-values
    listsamples<-sesame::RGChannelSetToSigSets(RGset)
    detectionpvals<-lapply(listsamples,function(sample) sesame::pOOBAH(sample, return.pval=TRUE))
    # old approach: detectionpvals<-lapply(listsamples,function(sample) sample@extra$pvals[["pOOBAH"]])
    detectionpvals<-do.call(cbind,detectionpvals)
    detectionpvalssave<-detectionpvals
    detectionpvals[detectionpvals>DetectionPvalCutoff]<-NA

  }

  if(DetectionPvalMethod=="ewastools"){

    detectionpvals<-ewastools::detectionP.minfi(RGset)
    detectionpvalssave<-detectionpvals
    detectionpvals[detectionpvals>DetectionPvalCutoff]<-NA

  }

  ## Also filtering out bad intensity
  ## Now will be NA if below detection p-value or bad intensity based on
  ## the number of beads or intensity values of zero
  overlapCpGsdetect<-intersect(rownames(indicatorgoodintensity),rownames(detectionpvals)) ## subset excludes the rs probes
  detectionpvals<-detectionpvals[overlapCpGsdetect,]
  indicatorgoodintensity<-indicatorgoodintensity[overlapCpGsdetect,colnames(detectionpvals)]
  detectionpvals<-detectionpvals*indicatorgoodintensity

  ## Dropping probes that failed in at least 5% of the samples
  numberfailedprobes<-apply(detectionpvals,1,function(x) length(x[is.na(x)]))
  prop.failedprobes<-numberfailedprobes/ncol(detectionpvals)
  ProbestoRemove<-names(prop.failedprobes)[which(prop.failedprobes>0.05)]

  ## Identify potential problem samples (poor intensity values for > 5% of remaining probes)
  ## First subsetting to the probes that did not fail in more than 5% of samples

  if(length(ProbestoRemove)>0){
    detectionpvals.temp<-detectionpvals[!(rownames(detectionpvals) %in% ProbestoRemove),]
  } else {
    detectionpvals.temp<-detectionpvals
  }
  numberfailed<-apply(detectionpvals.temp,2,function(x) length(x[is.na(x)]))
  prop.failed<-numberfailed/nrow(detectionpvals.temp)
  BasenamesDetectionPval<-names(prop.failed)[which(prop.failed>0.05)]
  cat("Samples with poor intensity values for >5% of remaining probes:",BasenamesDetectionPval,"\n")

  ##Getting rid of poorly performing samples and probes
  SamplestoRemove<-c(SexMixupV2,SexMixupV1,BasenamesDetectionPval)

  SamplestoRemove_Dataframe<-data.frame(Basename=pData(Mset.norm)$Basename,Sex_Wrong="No",TooManyFailedProbes="No")
  SamplestoRemove_Dataframe$Basename<-as.character(SamplestoRemove_Dataframe$Basename)
  SamplestoRemove_Dataframe$Sex_Wrong<-as.character(SamplestoRemove_Dataframe$Sex_Wrong)
  SamplestoRemove_Dataframe$TooManyFailedProbes<-as.character(SamplestoRemove_Dataframe$TooManyFailedProbes)
  SamplestoRemove_Dataframe$Sex_Wrong[SamplestoRemove_Dataframe$Basename %in% SexMixupV1]<-"Yes"
  SamplestoRemove_Dataframe$Sex_Wrong[SamplestoRemove_Dataframe$Basename %in% SexMixupV2]<-"Yes"
  SamplestoRemove_Dataframe$TooManyFailedProbes[SamplestoRemove_Dataframe$Basename %in% BasenamesDetectionPval]<-"Yes"
  SamplestoRemove_Dataframe<-merge(SamplestoRemove_Dataframe,contaminationdat,by="Basename")
  SamplestoRemove_Dataframe<-merge(SamplestoRemove_Dataframe,gettingmedianintensities,by="Basename")

  if(nrow(tempclusters)>0){
    SamplestoRemove_Dataframe<-merge(tempclusters,SamplestoRemove_Dataframe,by="Basename",all.y=TRUE)
  }
  write.csv(SamplestoRemove_Dataframe, paste(cohort,"_",analysisdate,"_Recommended_Samples_to_Remove.csv",sep=""), na="NA",row.names = FALSE)

  if(length(ProbestoRemove)>0){
    ProbestoRemove_Dataframe<-data.frame(CpG=ProbestoRemove,FailedInAtLeast5Percent="Yes")
    write.csv(ProbestoRemove_Dataframe, paste(cohort,"_",analysisdate,"_Recommended_Probes_to_Remove.csv",sep=""), na="NA",row.names = FALSE)
  }

  suggestedexclusions<-list(SamplestoRemove=SamplestoRemove,ProbestoRemove=ProbestoRemove,
                            DetectionPval=detectionpvalssave,IndicatorGoodIntensity=indicatorgoodintensity,logOddsContamin=meanlogodds)

  if(savelog){
    sink()
    sink(type="message")
  }

  return(suggestedexclusions)

}


### From the DNAmArray R Package: https://github.com/molepi/DNAmArray

probeFiltering <- function(RGset, cutbead=3, zeroint=TRUE, verbose=TRUE){

  if(class(RGset) != "RGChannelSetExtended")
    stop("RGset should be of class 'RGChannelSetExtended' in order to perform filtering on number of beads!")

  ##Filter on number of beads
  if(verbose)
    cat("Filtering on number of beads... \n")

  beadmat <- getNBeads(RGset)

  idBeadmat <- beadmat < cutbead
  ##beadmat[idBeadmat] <- NA

  if(verbose)
    cat("On average", round(100*sum(idBeadmat)/prod(dim(idBeadmat)), 2),"% of the probes (",nrow(idBeadmat),") have number of beads below", cutbead, "\n")

  ##Filter on Red and Green intensity <1
  if(zeroint) {
    if(verbose)
      cat("Filtering on zero intensities... \n")

    Grn <- getGreen(RGset)
    Red <- getRed(RGset)

    ##determine if Grn and/or Red intensities of type II probes are <1
    idT2 <- Grn[getProbeInfo(RGset, type = "II")$AddressA,] < 1 | Red[getProbeInfo(RGset, type = "II")$AddressA,] < 1

    ##determine if either Grn or Red intensities of Type I probes are <1
    idT1Grn <- Grn[c(getProbeInfo(RGset, type = "I-Green")$AddressA,
                     getProbeInfo(RGset, type = "I-Green")$AddressB),] < 1

    idT1Red <- Red[c(getProbeInfo(RGset, type = "I-Red")$AddressA,
                     getProbeInfo(RGset, type = "I-Red")$AddressB),] < 1

    if(verbose) {
      cat("On average", round(100*sum(idT2)/prod(dim(idT2)), 3),"% of the Type II probes (",nrow(idT2),") have Red and/or Green intensity below 1 \n")
      cat("On average", round(100*sum(idT1Grn)/prod(dim(idT1Grn)), 3),"% of the Type I probes (",nrow(idT1Grn),"), measured in Green channel, have intensity below 1 \n")
      cat("On average", round(100*sum(idT1Red)/prod(dim(idT1Red)), 3),"% of the Type I probes (",nrow(idT1Red),"), measured in Red channel, have intensity below 1 \n")
    }
  }

  ##combine all filtered results and set NA in Red and/or Green channels
  Red[idBeadmat] <- Grn[idBeadmat] <- NA

  if(zeroint) {
    if(verbose){
      cat("Set filtered probes in Red and/or Green channels to NA... \n")
    }

    for(i in 1:ncol(RGset)) {
      if(verbose & i%%100 == 0)
        cat("... done ",i," out of ",ncol(RGset)," ... \n")
      idRed <- c(names(which(idT2[,i])), names(which(idT1Red[,i])))
      midRed <- match(idRed, rownames(Red))
      Red[midRed, i] <- NA
      idGrn <- c(names(which(idT2[,i])), names(which(idT1Grn[,i])))
      midGrn <- match(idGrn, rownames(Grn))
      Grn[midGrn, i] <- NA
    }
  }

  RGChannelSet(Green = Grn, Red = Red,
               colData = colData(RGset),
               annotation = annotation(RGset))
}
